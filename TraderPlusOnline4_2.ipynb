{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNYQyKDNdx+Bbky6MDi9dO7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gulliyevn/DeepLearningModels/blob/main/TraderPlusOnline4_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGYyAa3cWSXc",
        "outputId": "bdd7c67d-e412-48f6-8938-fbdae9670a3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "üöÄ COMPLETE MULTI-ASSET FINE-TUNING FROM BTC v3.0\n",
            "================================================================================\n",
            "üìä Base model: BTC LSTM v3.0 (86.90% accuracy, +0.53% return)\n",
            "üéØ Strategy: Transfer Learning + Asset Embeddings\n",
            "üìÅ Save path: /content/drive/MyDrive/KERAS/MULTI_ASSET_FINE_TUNED\n",
            "üîß Features: 44 (exact match with v3.0)\n",
            "üöÄ COMPLETE MULTI-ASSET FINE-TUNING FROM BTC v3.0\n",
            "================================================================================\n",
            "\n",
            "üìä STEP 1: ANALYZING BTC v3.0 MODEL\n",
            "üîç ANALYZING BTC v3.0 MODEL...\n",
            "==================================================\n",
            "üì• Loading BTC v3.0 model...\n",
            "‚úÖ Model loaded: 14,595 parameters\n",
            "üì• Loading BTC scalers...\n",
            "‚úÖ Scalers loaded: ['features', 'xgb']\n",
            "\n",
            "üèóÔ∏è MODEL ARCHITECTURE ANALYSIS:\n",
            "  0: input_15m - InputLayer\n",
            "  1: lstm - LSTM (units: 32) (return_seq: True)\n",
            "  2: batch_normalization - BatchNormalization\n",
            "  3: lstm_1 - LSTM (units: 16) (return_seq: False)\n",
            "  4: batch_normalization_1 - BatchNormalization\n",
            "  5: dense - Dense (units: 16)\n",
            "  6: batch_normalization_2 - BatchNormalization\n",
            "  7: dropout - Dropout\n",
            "  8: prediction - Dense (units: 3)\n",
            "‚ùå Error analyzing BTC model: 'InputLayer' object has no attribute 'input_shape'\n",
            "‚ùå Failed to analyze BTC model\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# üöÄ COMPLETE MULTI-ASSET FINE-TUNING SYSTEM FROM BTC v3.0\n",
        "# Full pipeline: Analyze BTC v3.0 ‚Üí Extract Features ‚Üí Fine-tune ‚Üí Backtest\n",
        "# Based on proven 86.90% accuracy, +0.53% return model\n",
        "# ============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, LSTM, Dense, Dropout, BatchNormalization,\n",
        "    Embedding, Concatenate, Flatten, LayerNormalization\n",
        ")\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import joblib\n",
        "import os\n",
        "import gc\n",
        "from datetime import datetime, timedelta\n",
        "import json\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Google Colab Setup\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ============================================================================\n",
        "# üîß CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "# API Configuration\n",
        "API_KEY = '2f88eb1e7f9b49ef884557f27c95bd37'\n",
        "\n",
        "# Paths\n",
        "BTC_MODEL_PATH = '/content/drive/MyDrive/KERAS/btc_lstm_v3_multitimeframe.keras'\n",
        "BTC_SCALERS_PATH = '/content/drive/MyDrive/KERAS/btc_scalers_v3.pkl'\n",
        "SAVE_PATH = '/content/drive/MyDrive/KERAS/MULTI_ASSET_FINE_TUNED'\n",
        "os.makedirs(SAVE_PATH, exist_ok=True)\n",
        "\n",
        "# EXACT BTC v3.0 Feature List (from successful model)\n",
        "BTC_V3_FEATURES = [\n",
        "    'returns', 'log_returns', 'price_range', 'body_size', 'upper_shadow', 'lower_shadow',\n",
        "    'volume_sma', 'volume_ratio', 'price_volume', 'vwap', 'volatility', 'atr',\n",
        "    'rsi', 'macd', 'macd_signal', 'bb_upper', 'bb_lower',\n",
        "    'sma_5', 'ema_5', 'price_sma_5_ratio', 'sma_10', 'ema_10', 'price_sma_10_ratio',\n",
        "    'sma_20', 'ema_20', 'price_sma_20_ratio', 'sma_50', 'ema_50', 'price_sma_50_ratio',\n",
        "    'market_structure', 'liquidity_sweep', 'fvg_signal', 'order_block', 'displacement',\n",
        "    'h1_market_structure', 'h1_rsi', 'h1_macd', 'h1_volatility', 'h1_price_sma_20_ratio',\n",
        "    'm5_liquidity_sweep', 'm5_fvg_signal', 'm5_displacement', 'm5_volatility', 'm5_volume_ratio'\n",
        "]\n",
        "\n",
        "# Asset Configuration (AGGRESSIVE for more trading signals)\n",
        "ASSET_CONFIG = {\n",
        "    'FOREX': {\n",
        "        'pairs': ['EUR/USD', 'GBP/USD', 'USD/JPY'],\n",
        "        'profit_threshold': 0.0008,  # 0.08% - very aggressive\n",
        "        'volatility_factor': 1.0\n",
        "    },\n",
        "    'CRYPTO': {\n",
        "        'pairs': ['BTC/USD', 'ETH/USD'],\n",
        "        'profit_threshold': 0.005,   # 0.5% - aggressive but realistic\n",
        "        'volatility_factor': 3.0\n",
        "    },\n",
        "    'COMMODITIES': {\n",
        "        'pairs': ['XAU/USD'],\n",
        "        'profit_threshold': 0.002,   # 0.2% - gold is less volatile\n",
        "        'volatility_factor': 1.5\n",
        "    }\n",
        "}\n",
        "\n",
        "# BTC v3.0 Model Parameters\n",
        "SEQUENCE_LENGTH = 64  # Exact same as v3.0\n",
        "BTC_PROFIT_THRESHOLD = 0.004  # 0.4% from v3.0\n",
        "\n",
        "print(\"üöÄ COMPLETE MULTI-ASSET FINE-TUNING FROM BTC v3.0\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"üìä Base model: BTC LSTM v3.0 (86.90% accuracy, +0.53% return)\")\n",
        "print(f\"üéØ Strategy: Transfer Learning + Asset Embeddings\")\n",
        "print(f\"üìÅ Save path: {SAVE_PATH}\")\n",
        "print(f\"üîß Features: {len(BTC_V3_FEATURES)} (exact match with v3.0)\")\n",
        "\n",
        "# ============================================================================\n",
        "# üîç BTC V3.0 MODEL ANALYZER\n",
        "# ============================================================================\n",
        "\n",
        "class BTCModelAnalyzer:\n",
        "    \"\"\"Analyze BTC v3.0 model architecture and requirements\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.model = None\n",
        "        self.scalers = None\n",
        "        self.architecture = {}\n",
        "\n",
        "    def load_and_analyze(self) -> dict:\n",
        "        \"\"\"Load BTC v3.0 and analyze everything\"\"\"\n",
        "\n",
        "        print(\"üîç ANALYZING BTC v3.0 MODEL...\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        try:\n",
        "            # Load model\n",
        "            print(\"üì• Loading BTC v3.0 model...\")\n",
        "            self.model = load_model(BTC_MODEL_PATH)\n",
        "            print(f\"‚úÖ Model loaded: {self.model.count_params():,} parameters\")\n",
        "\n",
        "            # Load scalers\n",
        "            print(\"üì• Loading BTC scalers...\")\n",
        "            self.scalers = joblib.load(BTC_SCALERS_PATH)\n",
        "            print(f\"‚úÖ Scalers loaded: {list(self.scalers.keys())}\")\n",
        "\n",
        "            # Analyze architecture\n",
        "            print(\"\\nüèóÔ∏è MODEL ARCHITECTURE ANALYSIS:\")\n",
        "            for i, layer in enumerate(self.model.layers):\n",
        "                layer_info = f\"  {i}: {layer.name} - {layer.__class__.__name__}\"\n",
        "                if hasattr(layer, 'units'):\n",
        "                    layer_info += f\" (units: {layer.units})\"\n",
        "                if hasattr(layer, 'return_sequences'):\n",
        "                    layer_info += f\" (return_seq: {layer.return_sequences})\"\n",
        "                print(layer_info)\n",
        "\n",
        "            # Extract key architecture parameters\n",
        "            self.architecture = {\n",
        "                'input_shape': self.model.layers[0].input_shape,\n",
        "                'sequence_length': self.model.layers[0].input_shape[1],\n",
        "                'feature_count': self.model.layers[0].input_shape[2],\n",
        "                'lstm_layers': [],\n",
        "                'dense_layers': [],\n",
        "                'total_params': self.model.count_params()\n",
        "            }\n",
        "\n",
        "            # Find LSTM and Dense layers\n",
        "            for layer in self.model.layers:\n",
        "                if 'LSTM' in layer.__class__.__name__:\n",
        "                    self.architecture['lstm_layers'].append({\n",
        "                        'name': layer.name,\n",
        "                        'units': layer.units,\n",
        "                        'return_sequences': layer.return_sequences,\n",
        "                        'dropout': layer.dropout,\n",
        "                        'recurrent_dropout': layer.recurrent_dropout\n",
        "                    })\n",
        "                elif 'Dense' in layer.__class__.__name__:\n",
        "                    self.architecture['dense_layers'].append({\n",
        "                        'name': layer.name,\n",
        "                        'units': layer.units,\n",
        "                        'activation': layer.activation.__name__ if layer.activation else None\n",
        "                    })\n",
        "\n",
        "            print(f\"\\nüìä ARCHITECTURE SUMMARY:\")\n",
        "            print(f\"  Input shape: {self.architecture['input_shape']}\")\n",
        "            print(f\"  Sequence length: {self.architecture['sequence_length']}\")\n",
        "            print(f\"  Feature count: {self.architecture['feature_count']}\")\n",
        "            print(f\"  LSTM layers: {len(self.architecture['lstm_layers'])}\")\n",
        "            print(f\"  Dense layers: {len(self.architecture['dense_layers'])}\")\n",
        "            print(f\"  Total parameters: {self.architecture['total_params']:,}\")\n",
        "\n",
        "            # Verify feature compatibility\n",
        "            print(f\"\\nüîß FEATURE COMPATIBILITY CHECK:\")\n",
        "            expected_features = len(BTC_V3_FEATURES)\n",
        "            actual_features = self.architecture['feature_count']\n",
        "\n",
        "            if actual_features == expected_features:\n",
        "                print(f\"‚úÖ Features match: {actual_features} = {expected_features}\")\n",
        "            else:\n",
        "                print(f\"‚ö†Ô∏è Feature mismatch: {actual_features} ‚â† {expected_features}\")\n",
        "                print(f\"  Will adjust during fine-tuning\")\n",
        "\n",
        "            print(f\"\\n‚úÖ BTC v3.0 analysis completed!\")\n",
        "            return self.architecture\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error analyzing BTC model: {e}\")\n",
        "            return {}\n",
        "\n",
        "# ============================================================================\n",
        "# üìä EXACT BTC v3.0 FEATURE ENGINEERING\n",
        "# ============================================================================\n",
        "\n",
        "class ExactBTCFeatureEngineering:\n",
        "    \"\"\"Recreate EXACT same features as BTC v3.0\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def add_technical_indicators(df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"Add EXACT same technical indicators as BTC v3.0\"\"\"\n",
        "        df = df.copy()\n",
        "\n",
        "        # Price-based features (exact same as v3.0)\n",
        "        df['returns'] = df['close'].pct_change()\n",
        "        df['log_returns'] = np.log(df['close'] / df['close'].shift(1))\n",
        "        df['price_range'] = (df['high'] - df['low']) / df['close']\n",
        "        df['body_size'] = abs(df['close'] - df['open']) / df['close']\n",
        "        df['upper_shadow'] = (df['high'] - np.maximum(df['open'], df['close'])) / df['close']\n",
        "        df['lower_shadow'] = (np.minimum(df['open'], df['close']) - df['low']) / df['close']\n",
        "\n",
        "        # Volume features (exact same as v3.0)\n",
        "        df['volume_sma'] = df['volume'].rolling(20).mean()\n",
        "        df['volume_ratio'] = df['volume'] / df['volume_sma']\n",
        "        df['price_volume'] = df['close'] * df['volume']\n",
        "        df['vwap'] = df['price_volume'].rolling(20).sum() / df['volume'].rolling(20).sum()\n",
        "\n",
        "        # Volatility features (exact same as v3.0)\n",
        "        df['volatility'] = df['returns'].rolling(20).std()\n",
        "        df['atr'] = ((df['high'] - df['low']).rolling(14).mean())\n",
        "\n",
        "        # Momentum indicators (exact same as v3.0)\n",
        "        df['rsi'] = calculate_rsi(df['close'], 14)\n",
        "        df['macd'], df['macd_signal'] = calculate_macd(df['close'])\n",
        "        df['bb_upper'], df['bb_lower'] = calculate_bollinger_bands(df['close'])\n",
        "\n",
        "        # Moving averages (exact same as v3.0)\n",
        "        for period in [5, 10, 20, 50]:\n",
        "            df[f'sma_{period}'] = df['close'].rolling(period).mean()\n",
        "            df[f'ema_{period}'] = df['close'].ewm(period).mean()\n",
        "            df[f'price_sma_{period}_ratio'] = df['close'] / df[f'sma_{period}']\n",
        "\n",
        "        return df\n",
        "\n",
        "    @staticmethod\n",
        "    def add_smc_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"Add EXACT same SMC features as BTC v3.0\"\"\"\n",
        "\n",
        "        # Market structure (simplified but same logic)\n",
        "        df['market_structure'] = detect_market_structure_v3(df)\n",
        "        df['liquidity_sweep'] = detect_liquidity_sweeps_v3(df)\n",
        "        df['fvg_signal'] = detect_fair_value_gaps_v3(df)\n",
        "        df['order_block'] = detect_order_blocks_v3(df)\n",
        "\n",
        "        # Displacement (exact same logic)\n",
        "        df['displacement'] = 0\n",
        "        strong_moves = abs(df['returns']) > df['returns'].rolling(50).std() * 2\n",
        "        df.loc[strong_moves, 'displacement'] = np.sign(df.loc[strong_moves, 'returns'])\n",
        "\n",
        "        return df\n",
        "\n",
        "    @staticmethod\n",
        "    def create_multi_timeframe_features(data_dict: dict, primary_tf: str = '15min') -> pd.DataFrame:\n",
        "        \"\"\"Create EXACT same multi-timeframe features as BTC v3.0\"\"\"\n",
        "\n",
        "        print(\"üîß Creating exact BTC v3.0 features...\")\n",
        "\n",
        "        # Process base timeframe (15min)\n",
        "        if primary_tf not in data_dict:\n",
        "            raise ValueError(f\"Primary timeframe {primary_tf} not found\")\n",
        "\n",
        "        base_df = data_dict[primary_tf].copy()\n",
        "\n",
        "        # Add technical indicators\n",
        "        base_df = ExactBTCFeatureEngineering.add_technical_indicators(base_df)\n",
        "        base_df = ExactBTCFeatureEngineering.add_smc_features(base_df)\n",
        "\n",
        "        # Add hourly context (h1_ features)\n",
        "        if '1h' in data_dict:\n",
        "            hourly_df = data_dict['1h'].copy()\n",
        "            hourly_df = ExactBTCFeatureEngineering.add_technical_indicators(hourly_df)\n",
        "            hourly_df = ExactBTCFeatureEngineering.add_smc_features(hourly_df)\n",
        "\n",
        "            # Align timeframes (exact same as v3.0)\n",
        "            base_df = align_timeframes_v3(base_df, hourly_df, 'h1')\n",
        "\n",
        "        # Add 5min signals (m5_ features)\n",
        "        if '5min' in data_dict:\n",
        "            min5_df = data_dict['5min'].copy()\n",
        "            min5_df = ExactBTCFeatureEngineering.add_technical_indicators(min5_df)\n",
        "            min5_df = ExactBTCFeatureEngineering.add_smc_features(min5_df)\n",
        "\n",
        "            # Aggregate 5min to 15min (exact same as v3.0)\n",
        "            base_df = aggregate_5min_to_15min_v3(base_df, min5_df)\n",
        "\n",
        "        # Ensure all BTC v3.0 features exist\n",
        "        for feature in BTC_V3_FEATURES:\n",
        "            if feature not in base_df.columns:\n",
        "                base_df[feature] = 0\n",
        "                print(f\"  Added missing feature: {feature}\")\n",
        "\n",
        "        # Clean data (exact same as v3.0)\n",
        "        base_df = base_df.fillna(method='ffill').fillna(method='bfill')\n",
        "        base_df = base_df.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "\n",
        "        print(f\"‚úÖ Created {base_df.shape[1]} features (target: {len(BTC_V3_FEATURES)})\")\n",
        "\n",
        "        return base_df\n",
        "\n",
        "# ============================================================================\n",
        "# üß† FINE-TUNING ARCHITECTURE\n",
        "# ============================================================================\n",
        "\n",
        "class MultiAssetFineTuner:\n",
        "    \"\"\"Fine-tune BTC v3.0 for multi-asset trading\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.btc_model = None\n",
        "        self.fine_tuned_model = None\n",
        "        self.btc_scalers = None\n",
        "        self.asset_scalers = {}\n",
        "        self.asset_types = {}\n",
        "        self.sequence_length = SEQUENCE_LENGTH\n",
        "\n",
        "        # Asset mapping\n",
        "        asset_id = 0\n",
        "        for asset_class, config in ASSET_CONFIG.items():\n",
        "            for pair in config['pairs']:\n",
        "                self.asset_types[pair] = {\n",
        "                    'class': asset_class,\n",
        "                    'id': asset_id,\n",
        "                    'threshold': config['profit_threshold']\n",
        "                }\n",
        "                asset_id += 1\n",
        "\n",
        "        self.num_assets = len(self.asset_types)\n",
        "        print(f\"üè∑Ô∏è Asset mapping: {self.num_assets} assets total\")\n",
        "\n",
        "    def load_btc_model(self) -> bool:\n",
        "        \"\"\"Load the successful BTC v3.0 model\"\"\"\n",
        "\n",
        "        try:\n",
        "            print(\"üì• Loading proven BTC v3.0 model...\")\n",
        "\n",
        "            # Load model\n",
        "            self.btc_model = load_model(BTC_MODEL_PATH)\n",
        "            print(f\"‚úÖ BTC model loaded: {self.btc_model.count_params():,} params\")\n",
        "\n",
        "            # Load scalers\n",
        "            self.btc_scalers = joblib.load(BTC_SCALERS_PATH)\n",
        "            print(f\"‚úÖ BTC scalers loaded: {list(self.btc_scalers.keys())}\")\n",
        "\n",
        "            # Verify model architecture\n",
        "            input_shape = self.btc_model.layers[0].input_shape\n",
        "            print(f\"üìä BTC model input shape: {input_shape}\")\n",
        "            print(f\"üìä Expected: (None, {SEQUENCE_LENGTH}, {len(BTC_V3_FEATURES)})\")\n",
        "\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error loading BTC model: {e}\")\n",
        "            return False\n",
        "\n",
        "    def create_fine_tuned_architecture(self) -> Model:\n",
        "        \"\"\"Create fine-tuned architecture based on BTC v3.0\"\"\"\n",
        "\n",
        "        print(\"üß† Creating fine-tuned architecture...\")\n",
        "\n",
        "        # Get BTC model layers (freeze most, adapt last layers)\n",
        "        btc_input = self.btc_model.input\n",
        "\n",
        "        # Extract feature layers from BTC model (freeze LSTM backbone)\n",
        "        x = btc_input\n",
        "        for i, layer in enumerate(self.btc_model.layers[1:-2]):  # Skip input and last 2 layers\n",
        "            layer.trainable = False  # Freeze proven patterns\n",
        "            x = layer(x)\n",
        "            print(f\"  üîí Frozen: {layer.name}\")\n",
        "\n",
        "        # Get last LSTM output (this is our feature representation)\n",
        "        btc_features = x\n",
        "\n",
        "        # Asset embedding input\n",
        "        asset_input = Input(shape=(1,), name='asset_input')\n",
        "        asset_embedding = Embedding(\n",
        "            self.num_assets,\n",
        "            16,  # Smaller embedding for 6 assets\n",
        "            name='asset_embedding'\n",
        "        )(asset_input)\n",
        "        asset_embedding = Flatten(name='asset_flatten')(asset_embedding)\n",
        "\n",
        "        # Combine BTC features with asset embedding\n",
        "        combined_features = Concatenate(name='combine_btc_asset')([\n",
        "            btc_features, asset_embedding\n",
        "        ])\n",
        "\n",
        "        # Asset-aware adaptation layers (trainable)\n",
        "        adapted = Dense(24, activation='relu', name='asset_adaptation')(combined_features)\n",
        "        adapted = BatchNormalization(name='adaptation_bn')(adapted)\n",
        "        adapted = Dropout(0.4, name='adaptation_dropout')(adapted)\n",
        "\n",
        "        # Final classification (same as BTC v3.0)\n",
        "        output = Dense(3, activation='softmax', name='multi_asset_output')(adapted)\n",
        "\n",
        "        # Create fine-tuned model\n",
        "        fine_tuned_model = Model(\n",
        "            inputs=[btc_input, asset_input],\n",
        "            outputs=output,\n",
        "            name='MultiAssetFineTuned'\n",
        "        )\n",
        "\n",
        "        # Compile with smaller learning rate for fine-tuning\n",
        "        fine_tuned_model.compile(\n",
        "            optimizer=Adam(learning_rate=0.0001),  # 10x smaller than original\n",
        "            loss='categorical_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        # Count parameters\n",
        "        total_params = fine_tuned_model.count_params()\n",
        "        trainable_params = sum([layer.count_params() for layer in fine_tuned_model.layers if layer.trainable])\n",
        "        frozen_params = total_params - trainable_params\n",
        "\n",
        "        print(f\"‚úÖ Fine-tuned model created:\")\n",
        "        print(f\"  üìä Total parameters: {total_params:,}\")\n",
        "        print(f\"  üîí Frozen parameters: {frozen_params:,}\")\n",
        "        print(f\"  üéØ Trainable parameters: {trainable_params:,}\")\n",
        "        print(f\"  üîß Trainable ratio: {trainable_params/total_params:.1%}\")\n",
        "\n",
        "        return fine_tuned_model\n",
        "\n",
        "    def prepare_training_data(self, all_asset_data: dict) -> tuple:\n",
        "        \"\"\"Prepare training data with exact BTC v3.0 format\"\"\"\n",
        "\n",
        "        print(\"üìä Preparing fine-tuning dataset...\")\n",
        "\n",
        "        all_sequences = []\n",
        "        all_targets = []\n",
        "        all_asset_ids = []\n",
        "\n",
        "        for asset, df in all_asset_data.items():\n",
        "            if asset not in self.asset_types:\n",
        "                continue\n",
        "\n",
        "            print(f\"  Processing {asset}...\")\n",
        "\n",
        "            # Create trading signals (asset-specific thresholds)\n",
        "            profit_threshold = self.asset_types[asset]['threshold']\n",
        "            df = self.create_trading_signals(df, profit_threshold)\n",
        "\n",
        "            # Prepare exact BTC v3.0 features\n",
        "            feature_data = df[BTC_V3_FEATURES].values\n",
        "            target_data = df['target'].values\n",
        "\n",
        "            # Scale using BTC scaler for consistency\n",
        "            if 'features' in self.btc_scalers:\n",
        "                # Use BTC scaler if available\n",
        "                X_scaled = self.btc_scalers['features'].transform(feature_data)\n",
        "            else:\n",
        "                # Create asset-specific scaler\n",
        "                if asset not in self.asset_scalers:\n",
        "                    self.asset_scalers[asset] = StandardScaler()\n",
        "                    X_scaled = self.asset_scalers[asset].fit_transform(feature_data)\n",
        "                else:\n",
        "                    X_scaled = self.asset_scalers[asset].transform(feature_data)\n",
        "\n",
        "            # Create sequences (exact same as BTC v3.0)\n",
        "            asset_id = self.asset_types[asset]['id']\n",
        "\n",
        "            for i in range(self.sequence_length, len(X_scaled)):\n",
        "                all_sequences.append(X_scaled[i-self.sequence_length:i])\n",
        "                all_targets.append(target_data[i])\n",
        "                all_asset_ids.append(asset_id)\n",
        "\n",
        "        # Convert to arrays\n",
        "        X_sequences = np.array(all_sequences)\n",
        "        y_targets = np.array(all_targets)\n",
        "        asset_ids = np.array(all_asset_ids)\n",
        "\n",
        "        # Convert targets to categorical\n",
        "        y_categorical = to_categorical(y_targets, num_classes=3)\n",
        "\n",
        "        print(f\"‚úÖ Dataset prepared:\")\n",
        "        print(f\"  üìä Sequences: {X_sequences.shape}\")\n",
        "        print(f\"  üéØ Targets: {y_categorical.shape}\")\n",
        "        print(f\"  üè∑Ô∏è Assets: {len(np.unique(asset_ids))} unique\")\n",
        "\n",
        "        # Signal distribution\n",
        "        signal_counts = np.bincount(y_targets)\n",
        "        total_signals = len(y_targets)\n",
        "        print(f\"  üìà Signal distribution:\")\n",
        "        print(f\"    HOLD: {signal_counts[0]} ({signal_counts[0]/total_signals:.1%})\")\n",
        "        print(f\"    BUY:  {signal_counts[1]} ({signal_counts[1]/total_signals:.1%})\")\n",
        "        print(f\"    SELL: {signal_counts[2]} ({signal_counts[2]/total_signals:.1%})\")\n",
        "\n",
        "        return X_sequences, y_categorical, asset_ids\n",
        "\n",
        "    def create_trading_signals(self, df: pd.DataFrame, profit_threshold: float) -> pd.DataFrame:\n",
        "        \"\"\"Create trading signals with exact BTC v3.0 logic\"\"\"\n",
        "\n",
        "        # Exact same future return calculation as BTC v3.0\n",
        "        df['future_return'] = df['close'].shift(-15) / df['close'] - 1\n",
        "\n",
        "        # Exact same signal creation logic\n",
        "        conditions = [\n",
        "            df['future_return'] > profit_threshold,    # Buy signal\n",
        "            df['future_return'] < -profit_threshold,   # Sell signal\n",
        "        ]\n",
        "        choices = [1, 2]  # 1=Buy, 2=Sell\n",
        "        df['signal'] = np.select(conditions, choices, default=0)  # 0=Hold\n",
        "        df['target'] = df['signal']\n",
        "\n",
        "        return df\n",
        "\n",
        "    def fine_tune(self, all_asset_data: dict, epochs: int = 15) -> tf.keras.callbacks.History:\n",
        "        \"\"\"Fine-tune BTC v3.0 for multi-asset trading\"\"\"\n",
        "\n",
        "        print(\"üöÄ Starting fine-tuning process...\")\n",
        "\n",
        "        # Load BTC model\n",
        "        if not self.load_btc_model():\n",
        "            raise Exception(\"Failed to load BTC v3.0 model\")\n",
        "\n",
        "        # Create fine-tuned architecture\n",
        "        self.fine_tuned_model = self.create_fine_tuned_architecture()\n",
        "\n",
        "        # Prepare training data\n",
        "        X_sequences, y_categorical, asset_ids = self.prepare_training_data(all_asset_data)\n",
        "\n",
        "        # Temporal split (no shuffling for time series)\n",
        "        split_idx = int(len(X_sequences) * 0.8)\n",
        "\n",
        "        X_train = X_sequences[:split_idx]\n",
        "        y_train = y_categorical[:split_idx]\n",
        "        asset_train = asset_ids[:split_idx]\n",
        "\n",
        "        X_val = X_sequences[split_idx:]\n",
        "        y_val = y_categorical[split_idx:]\n",
        "        asset_val = asset_ids[split_idx:]\n",
        "\n",
        "        print(f\"üìä Training: {len(X_train)} samples\")\n",
        "        print(f\"üìä Validation: {len(X_val)} samples\")\n",
        "\n",
        "        # Callbacks for fine-tuning\n",
        "        callbacks = [\n",
        "            EarlyStopping(patience=8, restore_best_weights=True, monitor='val_accuracy'),\n",
        "            ReduceLROnPlateau(factor=0.5, patience=5, min_lr=0.00001),\n",
        "            ModelCheckpoint(\n",
        "                os.path.join(SAVE_PATH, 'best_fine_tuned_model.keras'),\n",
        "                save_best_only=True, monitor='val_accuracy'\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        # Fine-tuning with small learning rate\n",
        "        print(\"üéØ Fine-tuning BTC v3.0 for multi-asset trading...\")\n",
        "        history = self.fine_tuned_model.fit(\n",
        "            [X_train, asset_train], y_train,\n",
        "            validation_data=([X_val, asset_val], y_val),\n",
        "            epochs=epochs,\n",
        "            batch_size=16,  # Same as BTC v3.0\n",
        "            callbacks=callbacks,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        # Evaluation\n",
        "        val_pred = self.fine_tuned_model.predict([X_val, asset_val])\n",
        "        val_pred_classes = np.argmax(val_pred, axis=1)\n",
        "        val_true_classes = np.argmax(y_val, axis=1)\n",
        "        val_accuracy = accuracy_score(val_true_classes, val_pred_classes)\n",
        "\n",
        "        print(f\"‚úÖ Fine-tuned Model Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "        # Signal distribution analysis\n",
        "        print(f\"\\nüìä Validation Predictions:\")\n",
        "        pred_counts = np.bincount(val_pred_classes)\n",
        "        total_preds = len(val_pred_classes)\n",
        "        signal_names = ['HOLD', 'BUY', 'SELL']\n",
        "\n",
        "        for i, (name, count) in enumerate(zip(signal_names, pred_counts)):\n",
        "            print(f\"  {name}: {count} ({count/total_preds:.1%})\")\n",
        "\n",
        "        return history\n",
        "\n",
        "    def save_model(self):\n",
        "        \"\"\"Save fine-tuned model and components\"\"\"\n",
        "\n",
        "        print(\"üíæ Saving fine-tuned model...\")\n",
        "\n",
        "        # Save fine-tuned model\n",
        "        model_path = os.path.join(SAVE_PATH, 'multi_asset_fine_tuned_from_btc_v3.keras')\n",
        "        self.fine_tuned_model.save(model_path)\n",
        "\n",
        "        # Save scalers\n",
        "        scalers_path = os.path.join(SAVE_PATH, 'multi_asset_scalers.pkl')\n",
        "        all_scalers = {\n",
        "            'btc_scalers': self.btc_scalers,\n",
        "            'asset_scalers': self.asset_scalers\n",
        "        }\n",
        "        joblib.dump(all_scalers, scalers_path)\n",
        "\n",
        "        # Save metadata\n",
        "        metadata = {\n",
        "            'asset_types': self.asset_types,\n",
        "            'sequence_length': self.sequence_length,\n",
        "            'btc_features': BTC_V3_FEATURES,\n",
        "            'base_model': 'BTC v3.0 (86.90% accuracy, +0.53% return)',\n",
        "            'fine_tuning_approach': 'Transfer Learning + Asset Embeddings',\n",
        "            'created_at': datetime.now().isoformat()\n",
        "        }\n",
        "\n",
        "        metadata_path = os.path.join(SAVE_PATH, 'fine_tuned_metadata.json')\n",
        "        with open(metadata_path, 'w') as f:\n",
        "            json.dump(metadata, f, indent=2)\n",
        "\n",
        "        print(f\"‚úÖ Model saved to {SAVE_PATH}\")\n",
        "\n",
        "# ============================================================================\n",
        "# üìä REALISTIC DATA GENERATION\n",
        "# ============================================================================\n",
        "\n",
        "class RealisticDataGenerator:\n",
        "    \"\"\"Generate realistic market data for testing\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def generate_realistic_asset_data(symbol: str, periods: int = 1200) -> dict:\n",
        "        \"\"\"Generate realistic multi-timeframe data for an asset\"\"\"\n",
        "\n",
        "        # Asset-specific parameters\n",
        "        if 'USD/JPY' in symbol:\n",
        "            initial_price = 110\n",
        "            daily_vol = 0.008\n",
        "        elif any(crypto in symbol for crypto in ['BTC', 'ETH']):\n",
        "            initial_price = 50000 if 'BTC' in symbol else 3000\n",
        "            daily_vol = 0.025\n",
        "        elif 'XAU' in symbol:\n",
        "            initial_price = 1800\n",
        "            daily_vol = 0.012\n",
        "        else:  # FOREX\n",
        "            initial_price = 1.1\n",
        "            daily_vol = 0.006\n",
        "\n",
        "        # Generate 15min base data\n",
        "        dates_15m = pd.date_range(end=pd.Timestamp.now(), periods=periods, freq='15min')\n",
        "\n",
        "        # More realistic price generation\n",
        "        np.random.seed(42 + hash(symbol) % 100)\n",
        "\n",
        "        # Add multiple time components\n",
        "        trend = np.linspace(0, 0.05, periods) * np.random.choice([-1, 1])\n",
        "        daily_cycle = 0.02 * np.sin(np.linspace(0, periods/96*2*np.pi, periods))  # 96 = 15min periods per day\n",
        "        noise = np.random.normal(0, daily_vol/4, periods)\n",
        "\n",
        "        # Combine for realistic returns\n",
        "        returns = trend + daily_cycle + noise\n",
        "        returns = np.cumsum(returns)\n",
        "\n",
        "        prices_15m = initial_price * np.exp(returns)\n",
        "\n",
        "        # Create 15min OHLC\n",
        "        df_15m = pd.DataFrame({\n",
        "            'datetime': dates_15m,\n",
        "            'close': prices_15m\n",
        "        })\n",
        "\n",
        "        # Realistic OHLC generation\n",
        "        spread = daily_vol / 8\n",
        "        df_15m['high'] = df_15m['close'] * (1 + np.abs(np.random.normal(0, spread, periods)))\n",
        "        df_15m['low'] = df_15m['close'] * (1 - np.abs(np.random.normal(0, spread, periods)))\n",
        "        df_15m['open'] = df_15m['close'].shift(1).fillna(df_15m['close'])\n",
        "\n",
        "        # Ensure OHLC logic\n",
        "        df_15m['high'] = np.maximum(df_15m['high'], np.maximum(df_15m['open'], df_15m['close']))\n",
        "        df_15m['low'] = np.minimum(df_15m['low'], np.minimum(df_15m['open'], df_15m['close']))\n",
        "\n",
        "        # Volume based on volatility\n",
        "        price_change = np.abs(df_15m['close'].pct_change())\n",
        "        df_15m['volume'] = np.random.lognormal(12, 1, periods) * (1 + price_change * 3)\n",
        "\n",
        "        # Generate 1h data (from 15min)\n",
        "        df_1h = df_15m.set_index('datetime').resample('1h').agg({\n",
        "            'open': 'first',\n",
        "            'high': 'max',\n",
        "            'low': 'min',\n",
        "            'close': 'last',\n",
        "            'volume': 'sum'\n",
        "        }).reset_index()\n",
        "\n",
        "        # Generate 5min data (higher frequency)\n",
        "        dates_5m = pd.date_range(end=pd.Timestamp.now(), periods=periods*3, freq='5min')\n",
        "        returns_5m = np.random.normal(0, daily_vol/6, len(dates_5m))\n",
        "        returns_5m = np.cumsum(returns_5m)\n",
        "        prices_5m = initial_price * np.exp(returns_5m)\n",
        "\n",
        "        df_5m = pd.DataFrame({\n",
        "            'datetime': dates_5m,\n",
        "            'close': prices_5m\n",
        "        })\n",
        "\n",
        "        # Add OHLC for 5min\n",
        "        spread_5m = daily_vol / 12\n",
        "        df_5m['high'] = df_5m['close'] * (1 + np.abs(np.random.normal(0, spread_5m, len(dates_5m))))\n",
        "        df_5m['low'] = df_5m['close'] * (1 - np.abs(np.random.normal(0, spread_5m, len(dates_5m))))\n",
        "        df_5m['open'] = df_5m['close'].shift(1).fillna(df_5m['close'])\n",
        "\n",
        "        # Ensure OHLC logic\n",
        "        df_5m['high'] = np.maximum(df_5m['high'], np.maximum(df_5m['open'], df_5m['close']))\n",
        "        df_5m['low'] = np.minimum(df_5m['low'], np.minimum(df_5m['open'], df_5m['close']))\n",
        "\n",
        "        # Volume for 5min\n",
        "        price_change_5m = np.abs(df_5m['close'].pct_change())\n",
        "        df_5m['volume'] = np.random.lognormal(10, 1, len(dates_5m)) * (1 + price_change_5m * 3)\n",
        "\n",
        "        # Take last portion to match timeframe\n",
        "        df_5m = df_5m.tail(periods)\n",
        "\n",
        "        return {\n",
        "            '15min': df_15m,\n",
        "            '1h': df_1h,\n",
        "            '5min': df_5m\n",
        "        }\n",
        "\n",
        "    @staticmethod\n",
        "    def load_all_assets() -> dict:\n",
        "        \"\"\"Generate realistic data for all configured assets\"\"\"\n",
        "\n",
        "        print(\"üìä Generating realistic multi-timeframe data...\")\n",
        "\n",
        "        all_data = {}\n",
        "\n",
        "        for asset_class, config in ASSET_CONFIG.items():\n",
        "            print(f\"\\nüîÑ Generating {asset_class} data...\")\n",
        "\n",
        "            for symbol in config['pairs']:\n",
        "                print(f\"  üìà {symbol}...\")\n",
        "                asset_data = RealisticDataGenerator.generate_realistic_asset_data(symbol, 1200)\n",
        "                all_data[symbol] = asset_data\n",
        "\n",
        "        print(f\"\\n‚úÖ Generated data for {len(all_data)} assets\")\n",
        "        return all_data\n",
        "\n",
        "# ============================================================================\n",
        "# üìà COMPREHENSIVE BACKTESTER\n",
        "# ============================================================================\n",
        "\n",
        "class ComprehensiveBacktester:\n",
        "    \"\"\"Comprehensive backtesting for fine-tuned model\"\"\"\n",
        "\n",
        "    def __init__(self, model: MultiAssetFineTuner):\n",
        "        self.model = model\n",
        "\n",
        "    def backtest_asset(self, asset: str, asset_data: dict) -> dict:\n",
        "        \"\"\"Comprehensive backtest for single asset\"\"\"\n",
        "\n",
        "        print(f\"üìà Backtesting {asset}...\")\n",
        "\n",
        "        # Create features for this asset\n",
        "        df = ExactBTCFeatureEngineering.create_multi_timeframe_features(asset_data, '15min')\n",
        "\n",
        "        # Ensure exact feature compatibility\n",
        "        feature_data = df[BTC_V3_FEATURES].values\n",
        "\n",
        "        # Scale using appropriate scaler\n",
        "        if 'features' in self.model.btc_scalers:\n",
        "            X_scaled = self.model.btc_scalers['features'].transform(feature_data)\n",
        "        elif asset in self.model.asset_scalers:\n",
        "            X_scaled = self.model.asset_scalers[asset].transform(feature_data)\n",
        "        else:\n",
        "            scaler = StandardScaler()\n",
        "            X_scaled = scaler.fit_transform(feature_data)\n",
        "\n",
        "        # Create sequences\n",
        "        sequences = []\n",
        "        for i in range(SEQUENCE_LENGTH, len(X_scaled)):\n",
        "            sequences.append(X_scaled[i-SEQUENCE_LENGTH:i])\n",
        "\n",
        "        if not sequences:\n",
        "            return {}\n",
        "\n",
        "        X_sequences = np.array(sequences)\n",
        "        asset_id = self.model.asset_types[asset]['id']\n",
        "        asset_ids = np.full(len(sequences), asset_id)\n",
        "\n",
        "        # Predict\n",
        "        predictions = self.model.fine_tuned_model.predict([X_sequences, asset_ids], verbose=0)\n",
        "        pred_classes = np.argmax(predictions, axis=1)\n",
        "        confidences = np.max(predictions, axis=1)\n",
        "\n",
        "        # Align with prices\n",
        "        prices = df['close'].iloc[SEQUENCE_LENGTH:SEQUENCE_LENGTH + len(predictions)]\n",
        "        dates = df['datetime'].iloc[SEQUENCE_LENGTH:SEQUENCE_LENGTH + len(predictions)]\n",
        "\n",
        "        # Trading simulation\n",
        "        capital = 10000\n",
        "        trades = []\n",
        "        positions = []\n",
        "        current_position = 0\n",
        "\n",
        "        for i, (pred, conf, price, date) in enumerate(zip(pred_classes, confidences, prices, dates)):\n",
        "            if conf > 0.6:  # Only trade high confidence signals\n",
        "\n",
        "                if pred == 1 and current_position <= 0:  # Buy signal\n",
        "                    if current_position == -1:  # Close short first\n",
        "                        pnl = (entry_price - price) / entry_price\n",
        "                        capital *= (1 + pnl * 0.02)  # 2% position size\n",
        "                        trades.append({'type': 'close_short', 'pnl': pnl, 'price': price, 'date': date})\n",
        "\n",
        "                    # Open long\n",
        "                    current_position = 1\n",
        "                    entry_price = price\n",
        "                    trades.append({'type': 'buy', 'price': price, 'date': date})\n",
        "\n",
        "                elif pred == 2 and current_position >= 0:  # Sell signal\n",
        "                    if current_position == 1:  # Close long first\n",
        "                        pnl = (price - entry_price) / entry_price\n",
        "                        capital *= (1 + pnl * 0.02)  # 2% position size\n",
        "                        trades.append({'type': 'close_long', 'pnl': pnl, 'price': price, 'date': date})\n",
        "\n",
        "                    # Open short\n",
        "                    current_position = -1\n",
        "                    entry_price = price\n",
        "                    trades.append({'type': 'sell', 'price': price, 'date': date})\n",
        "\n",
        "            positions.append(current_position)\n",
        "\n",
        "        # Calculate comprehensive metrics\n",
        "        total_return = (capital - 10000) / 10000\n",
        "\n",
        "        # Trade analysis\n",
        "        pnl_trades = [t['pnl'] for t in trades if 'pnl' in t]\n",
        "        if pnl_trades:\n",
        "            win_rate = len([p for p in pnl_trades if p > 0]) / len(pnl_trades)\n",
        "            avg_win = np.mean([p for p in pnl_trades if p > 0]) if any(p > 0 for p in pnl_trades) else 0\n",
        "            avg_loss = np.mean([p for p in pnl_trades if p < 0]) if any(p < 0 for p in pnl_trades) else 0\n",
        "            profit_factor = abs(avg_win / avg_loss) if avg_loss != 0 else float('inf')\n",
        "        else:\n",
        "            win_rate = avg_win = avg_loss = profit_factor = 0\n",
        "\n",
        "        # Signal distribution\n",
        "        signal_dist = np.bincount(pred_classes, minlength=3)\n",
        "\n",
        "        # Accuracy vs actual signals\n",
        "        profit_threshold = self.model.asset_types[asset]['threshold']\n",
        "        df_signals = self.model.create_trading_signals(df, profit_threshold)\n",
        "        actual_signals = df_signals['target'].iloc[SEQUENCE_LENGTH:SEQUENCE_LENGTH + len(predictions)]\n",
        "        accuracy = accuracy_score(actual_signals, pred_classes)\n",
        "\n",
        "        return {\n",
        "            'asset': asset,\n",
        "            'total_return': total_return,\n",
        "            'accuracy': accuracy,\n",
        "            'win_rate': win_rate,\n",
        "            'profit_factor': profit_factor,\n",
        "            'num_trades': len([t for t in trades if 'pnl' in t]),\n",
        "            'avg_confidence': np.mean(confidences),\n",
        "            'signal_distribution': {\n",
        "                'HOLD': signal_dist[0],\n",
        "                'BUY': signal_dist[1],\n",
        "                'SELL': signal_dist[2]\n",
        "            },\n",
        "            'avg_win': avg_win,\n",
        "            'avg_loss': avg_loss,\n",
        "            'final_capital': capital\n",
        "        }\n",
        "\n",
        "    def backtest_all_assets(self, all_data: dict) -> pd.DataFrame:\n",
        "        \"\"\"Backtest all assets and return results\"\"\"\n",
        "\n",
        "        print(\"üöÄ Running comprehensive backtest...\")\n",
        "\n",
        "        results = []\n",
        "        for asset, asset_data in all_data.items():\n",
        "            if asset in self.model.asset_types:\n",
        "                result = self.backtest_asset(asset, asset_data)\n",
        "                if result:\n",
        "                    results.append(result)\n",
        "\n",
        "        if not results:\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        results_df = pd.DataFrame(results)\n",
        "\n",
        "        # Summary statistics\n",
        "        print(f\"\\nüìä BACKTEST SUMMARY:\")\n",
        "        print(f\"Assets tested: {len(results_df)}\")\n",
        "        print(f\"Average accuracy: {results_df['accuracy'].mean():.1%}\")\n",
        "        print(f\"Average return: {results_df['total_return'].mean():.2%}\")\n",
        "        print(f\"Average win rate: {results_df['win_rate'].mean():.1%}\")\n",
        "        print(f\"Assets with positive return: {(results_df['total_return'] > 0).sum()}\")\n",
        "\n",
        "        # Top performers\n",
        "        if len(results_df) > 0:\n",
        "            print(f\"\\nüèÜ TOP PERFORMERS:\")\n",
        "            top_performers = results_df.nlargest(3, 'total_return')\n",
        "            for _, row in top_performers.iterrows():\n",
        "                print(f\"  {row['asset']}: {row['total_return']:.2%} return, {row['accuracy']:.1%} accuracy\")\n",
        "\n",
        "        return results_df\n",
        "\n",
        "# ============================================================================\n",
        "# üîß HELPER FUNCTIONS (same as BTC v3.0)\n",
        "# ============================================================================\n",
        "\n",
        "def calculate_rsi(prices: pd.Series, period: int = 14) -> pd.Series:\n",
        "    \"\"\"Calculate RSI (exact same as BTC v3.0)\"\"\"\n",
        "    delta = prices.diff()\n",
        "    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
        "    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
        "    rs = gain / loss\n",
        "    rsi = 100 - (100 / (1 + rs))\n",
        "    return rsi.fillna(50)\n",
        "\n",
        "def calculate_macd(prices: pd.Series, fast: int = 12, slow: int = 26, signal: int = 9):\n",
        "    \"\"\"Calculate MACD (exact same as BTC v3.0)\"\"\"\n",
        "    ema_fast = prices.ewm(span=fast).mean()\n",
        "    ema_slow = prices.ewm(span=slow).mean()\n",
        "    macd = ema_fast - ema_slow\n",
        "    macd_signal = macd.ewm(span=signal).mean()\n",
        "    return macd.fillna(0), macd_signal.fillna(0)\n",
        "\n",
        "def calculate_bollinger_bands(prices: pd.Series, period: int = 20, std_dev: int = 2):\n",
        "    \"\"\"Calculate Bollinger Bands (exact same as BTC v3.0)\"\"\"\n",
        "    sma = prices.rolling(window=period).mean()\n",
        "    std = prices.rolling(window=period).std()\n",
        "    upper_band = sma + (std * std_dev)\n",
        "    lower_band = sma - (std * std_dev)\n",
        "    return upper_band.fillna(sma), lower_band.fillna(sma)\n",
        "\n",
        "def detect_market_structure_v3(df: pd.DataFrame, window: int = 20) -> pd.Series:\n",
        "    \"\"\"Market structure detection (same as BTC v3.0)\"\"\"\n",
        "    sma_short = df['close'].rolling(10).mean()\n",
        "    sma_long = df['close'].rolling(30).mean()\n",
        "    return np.where(sma_short > sma_long, 1, -1)\n",
        "\n",
        "def detect_liquidity_sweeps_v3(df: pd.DataFrame, lookback: int = 10) -> pd.Series:\n",
        "    \"\"\"Liquidity sweep detection (same as BTC v3.0)\"\"\"\n",
        "    recent_high = df['high'].rolling(lookback).max()\n",
        "    recent_low = df['low'].rolling(lookback).min()\n",
        "    high_sweep = (df['high'] > recent_high.shift(1)) & (df['close'] < recent_high.shift(1))\n",
        "    low_sweep = (df['low'] < recent_low.shift(1)) & (df['close'] > recent_low.shift(1))\n",
        "    return np.where(high_sweep, -1, np.where(low_sweep, 1, 0))\n",
        "\n",
        "def detect_fair_value_gaps_v3(df: pd.DataFrame) -> pd.Series:\n",
        "    \"\"\"FVG detection (simplified)\"\"\"\n",
        "    return np.random.choice([-1, 0, 1], size=len(df), p=[0.1, 0.8, 0.1])\n",
        "\n",
        "def detect_order_blocks_v3(df: pd.DataFrame) -> pd.Series:\n",
        "    \"\"\"Order block detection (same as BTC v3.0)\"\"\"\n",
        "    strong_move = abs(df['returns']) > df['returns'].rolling(20).std() * 2\n",
        "    return np.where(strong_move, np.sign(df['returns']), 0)\n",
        "\n",
        "def align_timeframes_v3(base_df: pd.DataFrame, htf_df: pd.DataFrame, prefix: str) -> pd.DataFrame:\n",
        "    \"\"\"Align timeframes (same as BTC v3.0)\"\"\"\n",
        "    base_df = base_df.copy()\n",
        "\n",
        "    # Simple alignment by forward fill\n",
        "    htf_features = ['market_structure', 'rsi', 'macd', 'volatility', 'price_sma_20_ratio']\n",
        "\n",
        "    for feature in htf_features:\n",
        "        if feature in htf_df.columns:\n",
        "            # Simple approach: repeat hourly values for 15min periods\n",
        "            base_df[f'{prefix}_{feature}'] = htf_df[feature].iloc[:len(base_df)].fillna(method='ffill')\n",
        "\n",
        "    return base_df\n",
        "\n",
        "def aggregate_5min_to_15min_v3(base_df: pd.DataFrame, min5_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Aggregate 5min to 15min (same as BTC v3.0)\"\"\"\n",
        "    base_df = base_df.copy()\n",
        "\n",
        "    # Simple aggregation approach\n",
        "    min5_features = ['liquidity_sweep', 'fvg_signal', 'displacement', 'volatility', 'volume_ratio']\n",
        "\n",
        "    for feature in min5_features:\n",
        "        if feature in min5_df.columns:\n",
        "            # Simple approach: use 5min values directly\n",
        "            base_df[f'm5_{feature}'] = min5_df[feature].iloc[:len(base_df)].fillna(0)\n",
        "\n",
        "    return base_df\n",
        "\n",
        "# ============================================================================\n",
        "# üîÆ REAL-TIME PREDICTION SYSTEM\n",
        "# ============================================================================\n",
        "\n",
        "class RealTimePredictionSystem:\n",
        "    \"\"\"Real-time prediction system for fine-tuned model\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.model = None\n",
        "        self.scalers = None\n",
        "        self.metadata = None\n",
        "\n",
        "    def load_fine_tuned_model(self) -> bool:\n",
        "        \"\"\"Load fine-tuned model and components\"\"\"\n",
        "\n",
        "        try:\n",
        "            # Load model\n",
        "            model_path = os.path.join(SAVE_PATH, 'multi_asset_fine_tuned_from_btc_v3.keras')\n",
        "            self.model = load_model(model_path)\n",
        "\n",
        "            # Load scalers\n",
        "            scalers_path = os.path.join(SAVE_PATH, 'multi_asset_scalers.pkl')\n",
        "            self.scalers = joblib.load(scalers_path)\n",
        "\n",
        "            # Load metadata\n",
        "            metadata_path = os.path.join(SAVE_PATH, 'fine_tuned_metadata.json')\n",
        "            with open(metadata_path, 'r') as f:\n",
        "                self.metadata = json.load(f)\n",
        "\n",
        "            print(\"‚úÖ Fine-tuned model loaded for real-time predictions\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error loading fine-tuned model: {e}\")\n",
        "            return False\n",
        "\n",
        "    def predict_asset(self, asset: str, asset_data: dict) -> dict:\n",
        "        \"\"\"Get real-time prediction for specific asset\"\"\"\n",
        "\n",
        "        if not self.model or asset not in self.metadata['asset_types']:\n",
        "            return {}\n",
        "\n",
        "        try:\n",
        "            # Create features\n",
        "            df = ExactBTCFeatureEngineering.create_multi_timeframe_features(asset_data, '15min')\n",
        "\n",
        "            # Get latest data point\n",
        "            latest_features = df[BTC_V3_FEATURES].tail(SEQUENCE_LENGTH).values\n",
        "\n",
        "            # Scale features\n",
        "            if 'btc_scalers' in self.scalers and 'features' in self.scalers['btc_scalers']:\n",
        "                X_scaled = self.scalers['btc_scalers']['features'].transform(latest_features)\n",
        "            else:\n",
        "                scaler = StandardScaler()\n",
        "                X_scaled = scaler.fit_transform(latest_features)\n",
        "\n",
        "            # Create sequence\n",
        "            X_sequence = X_scaled.reshape(1, SEQUENCE_LENGTH, -1)\n",
        "            asset_id = np.array([self.metadata['asset_types'][asset]['id']])\n",
        "\n",
        "            # Predict\n",
        "            prediction = self.model.predict([X_sequence, asset_id], verbose=0)[0]\n",
        "\n",
        "            signal_names = {0: \"HOLD üìä\", 1: \"BUY üü¢\", 2: \"SELL üî¥\"}\n",
        "            pred_class = np.argmax(prediction)\n",
        "            confidence = np.max(prediction)\n",
        "\n",
        "            return {\n",
        "                'asset': asset,\n",
        "                'signal': signal_names[pred_class],\n",
        "                'confidence': float(confidence),\n",
        "                'probabilities': {\n",
        "                    'hold': float(prediction[0]),\n",
        "                    'buy': float(prediction[1]),\n",
        "                    'sell': float(prediction[2])\n",
        "                },\n",
        "                'current_price': float(df['close'].iloc[-1])\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error predicting {asset}: {e}\")\n",
        "            return {}\n",
        "\n",
        "# ============================================================================\n",
        "# üöÄ MAIN EXECUTION\n",
        "# ============================================================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main execution pipeline\"\"\"\n",
        "\n",
        "    print(\"üöÄ COMPLETE MULTI-ASSET FINE-TUNING FROM BTC v3.0\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    try:\n",
        "        # Step 1: Analyze BTC v3.0 model\n",
        "        print(\"\\nüìä STEP 1: ANALYZING BTC v3.0 MODEL\")\n",
        "        analyzer = BTCModelAnalyzer()\n",
        "        architecture = analyzer.load_and_analyze()\n",
        "\n",
        "        if not architecture:\n",
        "            print(\"‚ùå Failed to analyze BTC model\")\n",
        "            return\n",
        "\n",
        "        # Step 2: Generate realistic data\n",
        "        print(f\"\\nüìä STEP 2: GENERATING REALISTIC DATA\")\n",
        "        data_generator = RealisticDataGenerator()\n",
        "        all_asset_data = data_generator.load_all_assets()\n",
        "\n",
        "        # Step 3: Process data with exact BTC v3.0 features\n",
        "        print(f\"\\nüîß STEP 3: CREATING EXACT BTC v3.0 FEATURES\")\n",
        "        processed_data = {}\n",
        "\n",
        "        for asset, asset_data in all_asset_data.items():\n",
        "            print(f\"  Processing {asset}...\")\n",
        "            df = ExactBTCFeatureEngineering.create_multi_timeframe_features(asset_data, '15min')\n",
        "            processed_data[asset] = df\n",
        "\n",
        "        print(f\"‚úÖ Processed {len(processed_data)} assets\")\n",
        "\n",
        "        # Step 4: Fine-tune BTC v3.0 model\n",
        "        print(f\"\\nüß† STEP 4: FINE-TUNING BTC v3.0 MODEL\")\n",
        "        fine_tuner = MultiAssetFineTuner()\n",
        "        history = fine_tuner.fine_tune(processed_data, epochs=15)\n",
        "\n",
        "        # Step 5: Save fine-tuned model\n",
        "        fine_tuner.save_model()\n",
        "\n",
        "        # Step 6: Comprehensive backtesting\n",
        "        print(f\"\\nüìà STEP 6: COMPREHENSIVE BACKTESTING\")\n",
        "        backtester = ComprehensiveBacktester(fine_tuner)\n",
        "        results_df = backtester.backtest_all_assets(all_asset_data)\n",
        "\n",
        "        # Save results\n",
        "        if not results_df.empty:\n",
        "            results_path = os.path.join(SAVE_PATH, 'fine_tuning_backtest_results.csv')\n",
        "            results_df.to_csv(results_path, index=False)\n",
        "            print(f\"üíæ Results saved: {results_path}\")\n",
        "\n",
        "            # Create comparison with BTC v3.0\n",
        "            print(f\"\\nüìä COMPARISON WITH BTC v3.0:\")\n",
        "            print(f\"BTC v3.0: 86.90% accuracy, +0.53% return\")\n",
        "            print(f\"Multi-Asset Fine-tuned: {results_df['accuracy'].mean():.1%} avg accuracy, {results_df['total_return'].mean():+.2%} avg return\")\n",
        "\n",
        "            # Asset class performance\n",
        "            print(f\"\\nüìã ASSET CLASS PERFORMANCE:\")\n",
        "            for asset_class, config in ASSET_CONFIG.items():\n",
        "                class_assets = [asset for asset in config['pairs'] if asset in results_df['asset'].values]\n",
        "                if class_assets:\n",
        "                    class_results = results_df[results_df['asset'].isin(class_assets)]\n",
        "                    print(f\"{asset_class}: {class_results['accuracy'].mean():.1%} accuracy, {class_results['total_return'].mean():+.2%} return\")\n",
        "\n",
        "        # Step 7: Demo real-time predictions\n",
        "        print(f\"\\nüîÆ STEP 7: DEMO REAL-TIME PREDICTIONS\")\n",
        "        predictor = RealTimePredictionSystem()\n",
        "\n",
        "        if predictor.load_fine_tuned_model():\n",
        "            print(f\"üìä Real-time predictions ready!\")\n",
        "\n",
        "            # Demo predictions for each asset\n",
        "            for asset in ['EUR/USD', 'BTC/USD', 'XAU/USD']:\n",
        "                if asset in all_asset_data:\n",
        "                    prediction = predictor.predict_asset(asset, all_asset_data[asset])\n",
        "                    if prediction:\n",
        "                        print(f\"  {asset}: {prediction['signal']} ({prediction['confidence']:.1%} confidence)\")\n",
        "\n",
        "        print(f\"\\n‚úÖ FINE-TUNING PIPELINE COMPLETED!\")\n",
        "        print(f\"üöÄ Transfer Learning from BTC v3.0 successful!\")\n",
        "        print(f\"üíæ All components saved to: {SAVE_PATH}\")\n",
        "        print(f\"üéØ Ready for production deployment!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error in main execution: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}